package com.java.stanford.nlp.examples;
import java.util.ArrayList;
import java.util.List;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


import com.java.stanford.nlp.core.Pipeline;

import edu.stanford.nlp.ling.CoreAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.CoreDocument;
import edu.stanford.nlp.pipeline.CoreSentence;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;


public class TokenizedExample {

	private static final Logger logger = LoggerFactory.getLogger(TokenizedExample.class);
	public static void start()
	{
		logger.info("");
    	StanfordCoreNLP stanfordCoreNlp=Pipeline.getPipeline();

    	
    	
 		String text="Hello ! Mr. Smith, this is  a not so correctly doing. Waht do you say ?";
 		CoreDocument document= new CoreDocument(text);
 		
 		
 				
 		stanfordCoreNlp.annotate(document);

 		
 		List<CoreLabel> listOfCoreLables =document.tokens();
 		List<CoreSentence> listOfSentence=document.sentences();
 	  
 		
 			
 		logger.info("Total words found "+listOfCoreLables.size());
 		logger.info("Total sentences found "+listOfSentence.size());
 		
 		ArrayList<String> listOfTokens=new ArrayList<String>();
 		ArrayList<String> listOfSentencess=new ArrayList<String>();
 		
 		for(CoreSentence sentence : listOfSentence)
	    {
 			listOfSentencess.add(sentence.text());
 		}
 		
 		
		for(CoreLabel label : listOfCoreLables)
	    {
			String partOfSpeech=label.get(CoreAnnotations.PartOfSpeechAnnotation.class);
			
			listOfTokens.add(label.originalText()+"-"+partOfSpeech+"-"+label.lemma());
 		}
		logger.info("List of Sentence "+listOfSentencess);
		logger.info("List of Words "+listOfTokens);
	 }//main 
}
