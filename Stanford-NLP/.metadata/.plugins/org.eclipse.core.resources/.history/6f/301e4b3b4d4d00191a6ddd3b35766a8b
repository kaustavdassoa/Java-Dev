package com.java.stanford.nlp.examples;
import java.util.List;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


import com.java.stanford.nlp.core.Pipeline;

import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.CoreDocument;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;


public class TokenizedExample {

	private static final Logger logger = LoggerFactory.getLogger(TokenizedExample.class);
	public static void start()
	{
		logger.info("Starting TokenizedExample.start()");
    	StanfordCoreNLP stanfordCoreNlp=Pipeline.getPipeline();

    	
    	
 		String text="This is a very long string ";
 		CoreDocument document= new CoreDocument(text);
 		
 		
 				
 		stanfordCoreNlp.annotate(document);

 		
 		List<CoreLabel> listOfCoreLables =document.tokens();
 		
 		if(listOfCoreLables == null)
 		{
 				logger.error("listOfCoreLables is NULL unable to tokenized "+document.text());
 				System.exit(0);
 		
 		}		
 		logger.info("Total label found "+listOfCoreLables.size());
 		
// 		for(CoreLabel label : listOfCoreLables)
// 		{
// 			logger.info(label.originalText());
// 		}
	}//main 
}
